{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tensorflow 로 LSTM 만들기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- tensorflow 를 사용하여 LSTM 을 만드는 방법 소개"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 사용되는 input(data) 와 output(label) 종류\n",
    "    - input  : 길이 20의 2진수, ex) 00010011111111111111\n",
    "    - output : 길이 20의 2진수, ex) 00010100000000000000\n",
    "    - output 은 input 에 1을 더한 값\n",
    "        - 00010011111111111111 + 1 = 00010100000000000000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.preprocessing import LabelBinarizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data Generation & Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1-1. 길이 20의 2진수 문자열 2^20 개를 생성"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* data_size : data 의 크기, 2^20\n",
    "* train_set_size : data_set 에서 train 으로 사용될 data 의 양, 2^18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data_size = 2**20\n",
    "train_set_size = 2**18\n",
    "\n",
    "data_set = ['{0:020b}'.format(i) for i in range(data_size)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* 생성된 데이터 표본\n",
      "00000000000000000000\n",
      "00000000000000000001\n",
      "00000000000000000010\n",
      "00000000000000000011\n",
      "00000000000000000100\n",
      "00000000000000000101\n",
      "00000000000000000110\n",
      "00000000000000000111\n",
      "00000000000000001000\n",
      "00000000000000001001\n"
     ]
    }
   ],
   "source": [
    "print('* 생성된 데이터 표본')\n",
    "for data in data_set[:10]:\n",
    "    print(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1-2. 길이 20의 배열로 분할하기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 문자열을 크기20의 배열 [20] 으로 분할한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ti  = []\n",
    "for i in data_set:\n",
    "    temp_list = []\n",
    "    for j in i:\n",
    "            temp_list.append(j)\n",
    "    ti.append(temp_list)\n",
    "temp_data_set = ti"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* 분할된 데이터 표본\n",
      "00000000000000000000 \n",
      "\t ->  ['0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0']\n",
      "00000000000000000001 \n",
      "\t ->  ['0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '1']\n",
      "00000000000000000010 \n",
      "\t ->  ['0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '1', '0']\n"
     ]
    }
   ],
   "source": [
    "print('* 분할된 데이터 표본')\n",
    "for origin, data in zip(data_set[:3], temp_data_set[:3]):\n",
    "    print(origin, '\\n\\t -> ', data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1-3. data 를 input 과 output 으로 나누기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* output = input + 1 이므로, input 과 output 의 크기는 2^20 - 1 이다.\n",
    "    * input 범위 : 0 ~ 2^20-1\n",
    "    * output 범위 : 1 ~ 2^20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "temp_data = []\n",
    "temp_target = []\n",
    "for idx in range(data_size - 1):\n",
    "    data = [int(val) for val in temp_data_set[idx][::-1]]\n",
    "    target = [int(val) for val in temp_data_set[idx+1][::-1]]\n",
    "    \n",
    "    temp_data.append(data)\n",
    "    temp_target.append(target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "temp_data = np.array(temp_data)\n",
    "temp_target = np.array(temp_target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 시계열 훈련을 위해 배열을 역순으로 반전 시킨후 저장\n",
    "* 이 과정이 없다면, 미래를 보고 과거를 맞추는 셈"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input :  [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0] , output :  [1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "input :  [1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0] , output :  [0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "input :  [0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0] , output :  [1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "for data, label in zip(temp_data[:3], temp_target[:3]):\n",
    "    print('전 : ', data,', 후 : ', label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1-4. shuffle 및 train, test 로 분리하기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* shuffle 이 더 효율적"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "shuffle = True\n",
    "\n",
    "if shuffle == True:\n",
    "    indices = np.random.permutation(range(data_size-1))\n",
    "\n",
    "    temp_data = temp_data[indices]\n",
    "    temp_target = temp_target[indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_input = temp_data[train_set_size:]\n",
    "test_output = temp_target[train_set_size:]\n",
    "train_input = temp_data[:train_set_size]\n",
    "train_output = temp_target[:train_set_size]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. LSTM 만들기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2-1. 변수 생성"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* batch_size : input 으로 들어가는 배열의 크기, 2^9\n",
    "* step_size : 시계열의 길이, 20\n",
    "* class_size : output 의 label 종류, 0 or 1 - 2개\n",
    "* num_hidden : 한 cell 의 state 의 크기, 32\n",
    "* dropout_probs : dropout 확률, 1, 데이터의 특성상 한자리의 값도 빠지면 예측이 불가능하여 1로 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_size = 2**9\n",
    "step_size = 20\n",
    "class_size = 2\n",
    "num_hidden = 32\n",
    "\n",
    "dropout_probs = 1.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* placeholder : memory <-> graphic card, 사이의 데이터를 전송해주는 bridge 개념\n",
    "* x, y 를 통하여 그래픽카드 메모리에 input 과 output 을 전달할 수 있음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x = tf.placeholder(tf.int32, [None, step_size])\n",
    "y = tf.placeholder(tf.int32, [None, step_size])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* embedding : word2vector 의 역할을 하는 함수\n",
    "    * [512, 20] -> [512, 20, 10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "vector_size = 10\n",
    "\n",
    "embeddings = tf.get_variable('embedding_matrix', [class_size, vector_size])\n",
    "rnn_inputs = tf.nn.embedding_lookup(embeddings, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* embedding 처리 전의 input 모습\n",
      "(?, 20)\n",
      "* embedding 처리 후의 input 모습\n",
      "(?, 20, 10)\n"
     ]
    }
   ],
   "source": [
    "print('* embedding 처리 전의 input 모습')\n",
    "print(x.shape)\n",
    "print('* embedding 처리 후의 input 모습')\n",
    "print(rnn_inputs.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2-2. LSTM Cell 생성"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 32 크기의 state 를 가지는 LSTM Cell 생성"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src = \"single rnn cell.png\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cell = tf.contrib.rnn.LSTMCell(num_hidden, state_is_tuple=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* input 에 dropout 을 걸어준다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cell = tf.contrib.rnn.DropoutWrapper(cell, input_keep_prob=dropout_probs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2-3. MultiLayer RNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Cell 을 중첩하여 구성한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src = \"multi rnn cell.png\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "num_layers = 2\n",
    "\n",
    "cell = tf.contrib.rnn.MultiRNNCell([cell] * num_layers, state_is_tuple=True)\n",
    "cell = tf.contrib.rnn.DropoutWrapper(cell, output_keep_prob=dropout_probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "outputs, _ = tf.nn.dynamic_rnn(cell, rnn_inputs, dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. output 가공"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 현재까지 기본이 되는 LSTM 을 구성하였다.\n",
    "* 앞으로는 Cell 을 구성하여 출력된 output 과 loss 를 어떻게 가공하느냐에 따라서, N to 1 혹은 N to N 으로 만들수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src = \"rnn types.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "                                                                                              ▲"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 앞으로의 코드는 \"many to many\" 의 RNN Cell 구성 방법이다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3-1. state 를 output 으로 만들기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 32 개의 state 를 \"0 or 1\" 로 만들기 위하여, [32, 2] 의 weight 와 [2] 의 bias 를 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "weight = tf.Variable(tf.truncated_normal([num_hidden, class_size]))\n",
    "bias = tf.Variable(tf.constant(0.1, shape=[class_size]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 현재의 output 의 크기\n",
    "* [512, 20, 32]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* weight 와 bias 를 쉽게 연산하기 위해 outputs 의 크기를 변경한다\n",
    "    * [512, 20, 32] -> [10240, 32]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "rnn_outputs = tf.reshape(outputs, [-1, num_hidden])\n",
    "logits = tf.matmul(rnn_outputs, weight) + bias"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 변경된 output 의 모습\n",
    "* [512, 20, 32] -> [10240, 32] -> [10240, 2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3-2. loss 선언"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* [512, 20] 의 output 을 logits 의 크기에 맞춰 변경 -> [10240, 1]\n",
    "* logits 와 label 간의 cross_entropy 를 계산해주는 함수를 이용하여 total_loss 를 연산"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y_as_list = tf.reshape(y, [-1])\n",
    "total_loss = tf.reduce_mean(tf.nn.sparse_softmax_cross_entropy_with_logits(logits=logits, labels=y_as_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3-3. prediction & accuracy 선언"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* logits 을 softmax 처리후 argmax 함수를 이용하여, [10240, 1] 로 만든다.\n",
    "* [10240, 1] 크기의 prediction 과 output 을 [512, 20] 로 만든다.\n",
    "* 비교함수를 이용하여 정확도를 계산"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "predictions = tf.argmax(tf.nn.softmax(logits), 1)\n",
    "predictions = tf.reshape(predictions, [-1, step_size])\n",
    "\n",
    "target = tf.reshape(y_as_list, [-1, step_size])\n",
    "\n",
    "matching = tf.reduce_all(tf.equal(predictions, tf.cast(target, tf.int64)), axis=1)\n",
    "\n",
    "accuracy = tf.reduce_mean(tf.cast(matching, dtype=tf.float32))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3-4. training algorithm 선택"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "optimizer = tf.train.AdagradOptimizer(0.1)\n",
    "train_step = optimizer.minimize(total_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "init_op = tf.global_variables_initializer()\n",
    "sess = tf.Session()\n",
    "sess.run(init_op)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 20 번의 epoch 를 사용하여 훈련, 정확도가 100% 가 되면 훈련 종료"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch -  0 , loss : 6.774e-03 , acc : 55.782\n",
      "Epoch -  1 , loss : 1.378e-03 , acc : 99.999\n",
      "Epoch -  2 , loss : 6.792e-04 , acc : 100.000\n"
     ]
    }
   ],
   "source": [
    "no_of_batches = int(len(train_input)/batch_size)\n",
    "epoch = 20\n",
    "for i in range(epoch):\n",
    "    ptr = 0\n",
    "    avg_acc = 0\n",
    "    for j in range(no_of_batches):\n",
    "        inp, out = train_input[ptr:ptr+batch_size], train_output[ptr:ptr+batch_size]\n",
    "        ptr+=batch_size\n",
    "        _, lss, acc = sess.run([train_step, total_loss, accuracy], feed_dict={x: inp, y: out})\n",
    "        avg_acc += acc / no_of_batches\n",
    "        \n",
    "    print(\"Epoch - \",str(i), ', loss : %.3e' % lss, ', acc : %.3f' % (avg_acc * 100))\n",
    "       \n",
    "    if avg_acc == 1:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3-5. Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test set size: 786431 , correct count: 786428\n"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "incorrect_idx_array = []\n",
    "for idx in range(int(np.ceil(len(test_input) / batch_size))):\n",
    "    s = idx * batch_size\n",
    "    e = s + batch_size\n",
    "    \n",
    "    match = sess.run(matching, feed_dict={x: test_input[s:e], y: test_output[s:e]})\n",
    "    \n",
    "    count += np.sum(match)\n",
    "    incorrect_idx_array = np.concatenate([incorrect_idx_array, np.where(match == False)[0] + s]).astype(int)\n",
    "    \n",
    "print('test set size: %d' % (len(test_input)), ', correct count: %d' % count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 실패한 data set 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==============================\n",
      "input     : 01111111111111111111\n",
      "output    : 10000000000000000000\n",
      "prediction: 01100000000000000000\n",
      "correct: False\n",
      "\n",
      "input     : 10111111111111111111\n",
      "output    : 11000000000000000000\n",
      "prediction: 10100000000000000000\n",
      "correct: False\n",
      "\n",
      "input     : 00111111111111111111\n",
      "output    : 01000000000000000000\n",
      "prediction: 00100000000000000000\n",
      "correct: False\n",
      "\n",
      "==============================\n"
     ]
    }
   ],
   "source": [
    "if len(incorrect_idx_array) != 0:\n",
    "    inp, out = test_input[incorrect_idx_array], test_output[incorrect_idx_array]\n",
    "else:\n",
    "    inp, out = [[1] + [0] * 19, [0] + [1] * 19], [[0, 1] + [0] * 18, [1] * 20]\n",
    "    \n",
    "    \n",
    "pred, match = sess.run([predictions, matching], feed_dict={x: inp, y: out})\n",
    "\n",
    "print('='*30)\n",
    "for a, b, c, d in zip(inp, out, pred, match):\n",
    "    print('input     : ', end='')\n",
    "    for o in a[::-1]:\n",
    "        print(o, end='')\n",
    "    print()\n",
    "    print('output    : ', end='')\n",
    "    for o in b[::-1]:\n",
    "        print(o, end='')\n",
    "    print()\n",
    "    print('prediction: ', end='')\n",
    "    for o in c[::-1]:\n",
    "        print(o, end='')\n",
    "    print()\n",
    "    print('correct: %r' % d)\n",
    "    print()\n",
    "print('='*30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
